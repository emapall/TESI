\subsection{Control System} A \grass{control system} is a triple $\Sigma=(\chi,f,U) $, where 
\begin{enumerate}
	\item $\chi$, representing the state of the system, is an \grass{pen} subset of $\R^n, \chi\subset\R^n$.
	\item $U$, representing the space of possible (\textit{istantaneous})controls, is an open subset of $\R^m,U\subset\R^m$
	\item $f: \chi \times cl(U) \rightarrow f(x,u)$ is a function which dictates the law with which the system evolves. $f$
	\begin{enumerate}
		\item is continuous
		\item the map $x \rightarrow f(x,u)$ is of class $C^1$ for each $u \in cl(U)$
	\end{enumerate}
\end{enumerate}

Since $f$ is function of the current state of the system and of the current control, the system's evolution does not explicitly depends on time. Of course, the law dictating the evolution of the system's status is 
\equaz{\statotdot=f(\statot,\mu(t))\label{e1.1}}
where obviously, for for each $t,\statot\in\chi$ is the "current" (at time $t$)state of the system, and $\mu(t)\in U$ is the current (at time $t$) control, dictated by the control law $\mu(t)$.


\subsection{Control and Trajectories}
The idea here is that we want some limitations on the function $t\rightarrow\mut$, because, starting from a certain state, we want the control to originate, through \ref{e1.1}, trajectories that, at least, "makes sense". So, given a control system \controlSystem  we define\\
\begin{itemize}
	\item An \grass{admissible control} is a \textit{measurable} map $\mu:I\rightarrow U$ where $I$ is a (time) intervale $I\subset\R$, and such that $t\fd f(x,\mut )$ is locally integrable for ceach $x\in\chi$
	\item we denote the set of admissible control defined on time interval $I$ by $\admContr{I}$	
	%https://www.overleaf.com/learn/latex/Mathematical_fonts for reference
	\item A \grass{controlled trajectory} is a pair $(\xi,\mu)$ where, for some time intervale $I\in\R$
		\lista{
			\item $\mu\in\admContr{I}$ is then a function expressing the control through which the system is driven in the time interval, and is an admissible control. This map will be simply be referred to as the \grass{control}.
			\item $\xi:I\fd \chi$ is the map linking the times in the interval to their corresponding state, which follows the law \ref{e1.1}. This map will be referred to as the \grass{trajectory}.
		}
	\item a \grass{controlled arc} is a controlled trajectory defined on a compact time interval.
\end{itemize}
The set of the controlled trajectories for a given control system \controlSystem is named Ctraj($\Sigma$), the set of the controlled arcs for the control system is named Carc($\Sigma$)


\subsection{Lagrangian, costs and optimal control problem(s)}
Since we will want to optimize a cost, we first have to define this objective function which has to be minimized. This will be the integral of another function, the lagrangian, along the path of the system in its evolution from the \textit{beginning} to the \textit{end} of the syof another function (Note: the integral is actually calculated by integrating on the time interval associated with the a controlled trajectory, so it's integrated on an interval of $\R$, not along a path in $\R^n$). So, given a control system \controlSystem
\begin{itemize}
	\item A \grass{Lagrangian}for $\Sigma\text{is a function }L:\chi\times cl(U)\fd\R$ such that
		\lista{
			\item L is continuous
			\item the function $x\fd L(x,u)$ is of class $C^1$ for each $u\in cl(U)$
		}
	
	\item given a Lagrangian $L$, it is said that a controlled trajectory \controlledTraj with relative time interval \I is \grass{L-acceptable} if the function $t\fd L(\statot,\mut)$ is integrable.
	
	\item given a Lagrangian $L$, the corresponding \grass{objective function} is the map $J_{\Sigma,L}:Ctraj(\Sigma)\fd\overline{\R}$ given by 
	\equaz{J_{\Sigma,L}\controlledTrajMath=\int_I L(\statot,\mut)dt}
	where we pose $J_{\Sigma,L}=\infty$ if \controlledTraj is not L-acceptable (if it's not integrable).\\
	The set of L-acceptable controlled trajectories (arcs) for the control system is denoted as Ctraj($\Sigma,L$) (or Carc($\Sigma,L$))
\end{itemize}
The idea here is that one should seek to minimize the objective function, with the "variable" to be tuned being the controlled trajectory. Usually though the problem faced is such that the system will start his evolution in a certain initial state, which resides in a set of possible initial conditions $S_0$, and some end conditions will be given, which means that in the end, the state of the system should reside in another set, $S_1$. Of course $S_0,S_1\subset\chi$. We thus call Carc($\Sigma,L,\szm,\som$) the set of controlled arcs for the control system \controlSystem with Lagrangian $L$, which have also the following properties
\lista{
\item every \controlledTraj in \carcSS is defined on a time interval of the form $[t_0,t_1]$ with $t_0<t_1;t_0,t_1\in\R $
\item every \controlledTraj in \carcSS then the said controlled arc is also in Carc($\Sigma,L$), which means it is an L-acceptable controlled arc
\item every \controlledTraj in \carcSS defined on the time interval $[t_0,t_1]$ then $\chi(t_0)\in\szm$ and $\chi(t_1)\in\som$.}

Now we can precisely define the optimization problem. There are actually two of these problem, depending on the fact that $t_0,t_1$ may or may not be fixed. We are going to consider the demonstration for the fixed interval one. So,
\subparagraph{Free interval optimal control problem} Let's have  \lista{
	\item a control system \controlSystem,
	\item a Lagrangian $L$,
	\item $\szm,\som\in\chi$ sets,}
	then a controlled trajectory {$(\xi_*,\mu_*)\in$\carcSS is a \grass{solution to the free interval optimal control problem} if \\$\forall\controlledTrajMath\in$\carcSS,  $\objFunction{(\xi_*,\mu_*)}<\objFunction{\controlledTrajMath}$.\\
	The set of all the possible solutions is denoted as $\mathfrak{P}(\Sigma,L,\szm,\som)$.
\subparagraph{Fixed interval optimal control problem} Let's have  \lista{
	\item a control system \controlSystem,
	\item a Lagrangian $L$,
	\item $\szm,\som\in\chi$ sets,
	\item a time interval $[t_0,t_1]$ with $t_0<t_1;t_0,t_1\in\R$}
	then a controlled trajectory {$(\xi_*,\mu_*)\in$\carcSSfix is a \grass{solution to the fixed interval optimal control problem} if \\$\forall\controlledTrajMath\in$\carcSSfix,  $ \objFunction{(\xi_*,\mu_*)}<\objFunction{\controlledTrajMath}$.\\
	The set of all the possible solutions is denoted as $\mathfrak{P}(\Sigma,L,\szm,\som,[t_0,t_1])$.
\subparagraph{A simple example} The problem in which the cost is the time with which the system is driven from \sz to \so is simply a free interval optimal control problem, in which there is a control system with Lagrangian $L(x,u)=1$.


\subsection{Hamiltonians}
The maximum principle is related with the maximization of a Hamiltonian associated with a control system with a certain Lagrangian, so we have the following definitions.\\
Let \controlSystem be a control system, $L$ a Lagrangian, then
\lista{
	\item the \grass{Hamiltonian} is the function $H_\Sigma:\chi\times\R^n\times U\fd \R$ given by
		\gatherNo{H_\Sigma(x,p,u)=\langle p,f(x,u)\rangle}
	\item the \grass{extendend Hamiltonian} is the function $H_{\Sigma,L}:\chi\times\R^n\times U\fd \R$ given by
		\begin{equation*}
		H_\Sigma(x,p,u)=\langle p,f(x,u)\rangle+L(x,u)=H_\Sigma(x,p,u)+L(x,u)
		\end{equation*}
	\item the \grass{maximum Hamiltonian} is the function $H_{\Sigma}^{max}:\chi\times\R^n\fd \overline\R$ given by	
		\gatherNo{H_{\Sigma}^{max}=sup\{H_\Sigma(x,p,u)|u\in U\}}
	\item the \grass{maximum extended Hamiltonian} is the function $H_{\Sigma,L}^{max}:\chi\times\R^n\fd \overline\R$ given by	
		\gatherNo{H_{\Sigma,L}^{max}=sup\{H_{\Sigma,L}(x,p,u)|u\in U\}}
	\item the variable $p$ is sometimes called \grass{costate}
}


\subsection{Adjoint response}
There are another two quantities, namely the adjoint response and the control variations (with the associated variational equation), which are very important in the understanding of the maximum principle. The part relative to adjoint response will now be stated, because it appears in the statement of the principle, while the part concerning brings along concepts that are useful to the demonstration and to the understanding of the geometrical significance of the principle. \\
So now let \controlSystem be a control system, and \lista{
	\item $\controlledTrajMath\in Ctraj(\Sigma)$ be a controlled trajectory with time interval $I$, then we define the \grass{adjoint response} for $\Sigma$ along \controlledTraj as a locally absolutely continous map $\lambda:I\fd\R^n$ which also satisfies the following differential equation(s):
		\begin{multiLineSingleNumber}
			\statotdot=\boldsymbol{D}_2H_\Sigma(\statot,\lambdat,\mut)\text{    }(=f(x,u))\\
			\lambdat=-\boldsymbol{D}_1H_\Sigma(\statot,\lambdat,\mut)
			\label{adjoint-hamiltonian}
		\end{multiLineSingleNumber}
	we will see later that this last equation can reach another equivalent form.
	\item if $L$ is a Lagrangian and $\controlledTrajMath\in Ctraj(\Sigma,L)$is an L-acceptable controlled trajectory with time interval $I$, we then define the \grass{adjoint response} for $(\Sigma,L)$ along \controlledTraj as a locally absolutely continous map $\lambda:I\fd\R^n$ which also satisfies the following differential equation(s):
	\begin{multiLineSingleNumber}
		\statotdot=\boldsymbol{D}_2H_{\Sigma,L}(\statot,\lambdat,\mut)\text{    }(=f(x,u))\\
		\lambdat=-\boldsymbol({D}_1H_{\Sigma,L}(\statot,\lambdat,\mut)
	\end{multiLineSingleNumber}  
}


\subsection{Smooth constraint sets}
Part of the maximum principle deals with the case in which \sz and \so are "smooth", so we might define a \grass{smooth constraint set S} as a subset of the set of possible (control)system states $S\subset\chi$ such that there exists a $C^1$ function $\Phi:\chi\fd\R^k$, such that $S=\Phi^{-1}(0)$ and  also $\Dder\Phi(x)$ is surjective for each $x\in S$

\subsection{Reachable set}
Let \controlSystem be a control system, $x_0\in\chi$ be an initial condition for eq. \ref{e1.1}, $\tzto\subset\R$ a time interval, $\mu\in\admContr{x_0,t_0,\tzto}$. We then define \lista{
	\item the \grass{reachable set} from $x_0$ at $t_0$ in time $t_1-t_0$ as 
	\[\reachSetMath{t_1}=\{\trajWinCondMath{t_1}|\mu\in\admContr{\tzto} \}  \]
	
	\item the \grass{reachable set } from $x_0$ at $t_0$ as
	\[\mathfrak{R}(x_0,t_0)=\cup_{t_1\in[t_0,\infty]} \reachSetMath{t_1}  \]
	
}
Little note: since f does not depend explicitly on time, then \reachSet{t_1}$=\mathfrak{R}(x_0,0,t_0)$.